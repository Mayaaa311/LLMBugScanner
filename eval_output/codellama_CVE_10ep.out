---------------------------------------
Begin Slurm Prolog: Nov-23-2024 12:57:36
Job ID:    970070
User ID:   zyahn3
Account:   scs
Job name:  eval_bugscanner
Partition: ice-gpu
---------------------------------------
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/condabin/conda
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/conda
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/conda-env
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/activate
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/deactivate
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/profile.d/conda.sh
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/fish/conf.d/conda.fish
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/shell/condabin/Conda.psm1
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/shell/condabin/conda-hook.ps1
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/profile.d/conda.csh
no change     /home/hice1/zyahn3/.bashrc
No action taken.
/home/hice1/zyahn3/.conda/envs/BugScanner
2024-11-23 12:57:44,720 - INFO - Initializing auditor models...
2024-11-23 12:57:44,721 - INFO - Auditor models: finetune/model/codellama/codellama_CVE_10ep/
2024-11-23 12:57:44,721 - INFO - Initializing critic model: finetune/model/gemma/gemma_CVE_10ep/
2024-11-23 12:57:44,721 - INFO - Initializing ranker model: finetune/model/gemma/gemma_CVE_10ep/
2024-11-23 12:57:44,721 - INFO - Initializing parser model: finetune/model/gemma/gemma_CVE_10ep/
2024-11-23 12:57:44,721 - INFO - Initializing BugScanner with the given models...
2024-11-23 12:57:44,721 - INFO - BugScanner initialization completed.
2024-11-23 12:57:44,722 - INFO - Starting the bug scanning pipeline with Top-K = 5...
2024-11-23 12:57:44,722 - INFO - Found 109 .sol files in the folder: data_full/0.8splitCVE_clean
2024-11-23 12:57:44,722 - INFO - Output will be saved in: eval_result/codellama_CVE_10ep
Unused kwargs: ['load_in_8bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 37.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.20s/it]
Unused kwargs: ['load_in_8bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]
  0%|          | 0/109 [00:00<?, ?it/s]/home/hice1/zyahn3/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:668: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `1.5` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.
  warnings.warn(
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 970070.0 ON atl1-1-03-012-18-0 CANCELLED AT 2024-11-23T13:02:53 ***
slurmstepd: error: *** JOB 970070 ON atl1-1-03-012-18-0 CANCELLED AT 2024-11-23T13:02:53 ***
---------------------------------------
Begin Slurm Epilog: Nov-23-2024 13:02:56
Job ID:        970070
Array Job ID:  _4294967294
User ID:       zyahn3
Account:       scs
Job name:      eval_bugscanner
Resources:     cpu=1,gres/gpu:h100=1,mem=80G,node=1
Rsrc Used:     cput=00:05:18,vmem=0,walltime=00:05:18,mem=6592K,energy_used=0
Partition:     ice-gpu
Nodes:         atl1-1-03-012-18-0
---------------------------------------
