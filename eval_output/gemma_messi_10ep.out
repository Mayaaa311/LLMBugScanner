---------------------------------------
Begin Slurm Prolog: Nov-23-2024 09:44:56
Job ID:    969047
User ID:   zyahn3
Account:   scs
Job name:  eval_bugscanner
Partition: ice-gpu
---------------------------------------
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/condabin/conda
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/conda
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/conda-env
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/activate
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/bin/deactivate
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/profile.d/conda.sh
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/fish/conf.d/conda.fish
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/shell/condabin/Conda.psm1
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/shell/condabin/conda-hook.ps1
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /usr/local/pace-apps/manual/packages/anaconda3/2023.03/etc/profile.d/conda.csh
no change     /home/hice1/zyahn3/.bashrc
No action taken.
/home/hice1/zyahn3/.conda/envs/BugScanner
2024-11-23 09:45:07,468 - INFO - Initializing auditor models...
2024-11-23 09:45:07,469 - INFO - Auditor models: finetune/model/gemma/gemma_messi_10ep/
2024-11-23 09:45:07,469 - INFO - Initializing critic model: finetune/model/gemma/gemma_messi_10ep/
2024-11-23 09:45:07,469 - INFO - Initializing ranker model: finetune/model/gemma/gemma_messi_10ep/
2024-11-23 09:45:07,469 - INFO - Initializing parser model: finetune/model/gemma/gemma_messi_10ep/
2024-11-23 09:45:07,469 - INFO - Initializing BugScanner with the given models...
2024-11-23 09:45:07,469 - INFO - BugScanner initialization completed.
2024-11-23 09:45:07,469 - INFO - Starting the bug scanning pipeline with Top-K = 5...
2024-11-23 09:45:07,470 - INFO - Found 109 .sol files in the folder: data_full/0.8splitCVE_clean
2024-11-23 09:45:07,470 - INFO - Output will be saved in: eval_result/gemma_messi_10ep
Unused kwargs: ['load_in_8bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]
Unused kwargs: ['load_in_8bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]
  0%|          | 0/109 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
  0%|          | 0/109 [17:44<?, ?it/s]
2024-11-23 10:03:31,632 - INFO - Bug scanning pipeline completed for all files in 1104.17 seconds.
using cuda
Attempted to get_model_instance for name finetune/model/gemma/gemma_messi_10ep/ and got model_class None
Attempted to get_model_instance for name finetune/model/gemma/gemma_messi_10ep/ and got model_class None
Attempted to get_model_instance for name finetune/model/gemma/gemma_messi_10ep/ and got model_class None
Attempted to get_model_instance for name finetune/model/gemma/gemma_messi_10ep/ and got model_class None
About to load all models
---- Running Auditor(s) ----
MODEL WAS INVOKED
Input prompt is: tensor([[256000,   1645,    108,  ..., 256000, 105776,    108]],
       device='cuda:0') with length torch.Size([1, 1556])
Output prompt is: tensor([[256000,   1645,    108,  ..., 100170, 100170, 100170]],
       device='cuda:0') with shape torch.Size([1, 21556])
Auditor response written to :  eval_result/gemma_messi_10ep/2018-12080/auditor/finetune_model_gemma_gemma_messi_10ep__auditor.json
---------------------------------------
Begin Slurm Epilog: Nov-23-2024 10:03:32
Job ID:        969047
Array Job ID:  _4294967294
User ID:       zyahn3
Account:       scs
Job name:      eval_bugscanner
Resources:     cpu=1,gres/gpu:h100=1,mem=80G,node=1
Rsrc Used:     cput=00:18:36,vmem=0,walltime=00:18:36,mem=6840K,energy_used=0
Partition:     ice-gpu
Nodes:         atl1-1-03-012-18-0
---------------------------------------
