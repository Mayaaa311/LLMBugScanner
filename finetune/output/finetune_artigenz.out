---------------------------------------
Begin Slurm Prolog: Nov-11-2024 13:04:14
Job ID:    926079
User ID:   zyahn3
Account:   scs
Job name:  finetuningNxcode
Partition: coc-gpu
---------------------------------------

CondaError: Run 'conda init' before 'conda deactivate'

/home/hice1/zyahn3/.conda/envs/BugScanner
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]
Traceback (most recent call last):
  File "/storage/ice1/5/9/zyahn3/LLMBugScanner/finetune/finetune_gemma.py", line 28, in <module>
    model, tokenizer = setup_chat_format(model, tokenizer)
  File "/home/hice1/zyahn3/.local/lib/python3.10/site-packages/trl/models/utils.py", line 101, in setup_chat_format
    raise ValueError(
ValueError: Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None
srun: error: atl1-1-03-007-33-0: task 0: Exited with exit code 1
---------------------------------------
Begin Slurm Epilog: Nov-11-2024 13:04:36
Job ID:        926079
Array Job ID:  _4294967294
User ID:       zyahn3
Account:       scs
Job name:      finetuningNxcode
Resources:     cpu=1,gres/gpu:a100=1,mem=80G,node=1
Rsrc Used:     cput=00:00:22,vmem=0,walltime=00:00:22,mem=32K,energy_used=0
Partition:     coc-gpu
Nodes:         atl1-1-03-007-33-0
---------------------------------------
